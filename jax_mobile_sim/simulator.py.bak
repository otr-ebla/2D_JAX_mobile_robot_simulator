"""Simulation utilities for mobile robots and humans in indoor maps."""
from __future__ import annotations

from dataclasses import dataclass
import jax
import jax.numpy as jnp

from .environment import IndoorMapBatch


@dataclass
class SimulationConfig:
    """Configuration parameters for the simulator."""

    dt: float = 0.1
    robot_radius: float = 0.2
    person_radius: float = 0.2
    max_robot_speed: float = 1.0
    max_robot_angular_speed: float = 1.5
    max_person_speed: float = 0.9
    person_noise_scale: float = 0.5
    dynamics_substeps: int = 4
    lidar_updates_per_step: int = 12


@dataclass
class AgentState:
    position: jnp.ndarray  # (..., 2)
    velocity: jnp.ndarray  # (..., 2)


@dataclass
class RobotState(AgentState):
    heading: jnp.ndarray  # (...,)


@dataclass
class PeopleState(AgentState):
    pass


@dataclass
class SimulationState:
    robots: RobotState
    people: PeopleState


def _clip_speed(velocity: jnp.ndarray, max_speed: float) -> jnp.ndarray:
    speed = jnp.linalg.norm(velocity, axis=-1, keepdims=True)
    safe_speed = jnp.where(speed > 1e-6, speed, 1.0)
    factor = jnp.minimum(1.0, max_speed / safe_speed)
    return velocity * factor


def _wrap_angle(angle: jnp.ndarray) -> jnp.ndarray:
    """Wrap angles to [-pi, pi)."""

    return jnp.arctan2(jnp.sin(angle), jnp.cos(angle))


def _resolve_axis_aligned_collisions(
    positions: jnp.ndarray,
    radius: float,
    segments: jnp.ndarray,
    mask: jnp.ndarray,
) -> jnp.ndarray:
    """Push disc agents outside of walls represented by line segments."""

    def resolve_env(pos_env, seg_env, mask_env):
        radius_val = jnp.asarray(radius, dtype=pos_env.dtype)

        def collide_with_segment(pos, segment, is_valid):
            x0, y0, x1, y1 = segment
            is_vertical = jnp.isclose(x0, x1)
            is_horizontal = jnp.isclose(y0, y1)

            def vertical_case():
                xw = x0
                ymin = jnp.minimum(y0, y1)
                ymax = jnp.maximum(y0, y1)
                dx = pos[0] - xw
                within = (pos[1] >= ymin) & (pos[1] <= ymax)
                penetration = radius_val - jnp.abs(dx)
                penetration = jnp.maximum(0.0, penetration)
                push_dir = jnp.where(dx >= 0.0, 1.0, -1.0).astype(pos.dtype)
                delta = jnp.array([push_dir * penetration, 0.0], dtype=pos.dtype)
                return jnp.where(within, pos + delta, pos)

            def horizontal_case():
                yw = y0
                xmin = jnp.minimum(x0, x1)
                xmax = jnp.maximum(x0, x1)
                dy = pos[1] - yw
                within = (pos[0] >= xmin) & (pos[0] <= xmax)
                penetration = radius_val - jnp.abs(dy)
                penetration = jnp.maximum(0.0, penetration)
                push_dir = jnp.where(dy >= 0.0, 1.0, -1.0).astype(pos.dtype)
                delta = jnp.array([0.0, push_dir * penetration], dtype=pos.dtype)
                return jnp.where(within, pos + delta, pos)

            new_pos = jax.lax.cond(
                is_vertical,
                lambda _: vertical_case(),
                lambda _: jax.lax.cond(
                    is_horizontal, lambda __: horizontal_case(), lambda __: pos, None
                ),
                operand=None,
            )
            return jax.lax.select(is_valid, new_pos, pos)

        def resolve_single(pos):
            def scan_fn(p, data):
                segment, is_valid = data
                new_p = collide_with_segment(p, segment, is_valid)
                return new_p, None

            new_pos, _ = jax.lax.scan(scan_fn, pos, (seg_env, mask_env))
            return new_pos

        return jax.vmap(resolve_single)(pos_env)

    return jax.vmap(resolve_env)(positions, segments, mask)


def step_simulation(
    state: SimulationState,
    robot_actions: jnp.ndarray,
    map_batch: IndoorMapBatch,
    config: SimulationConfig,
    key: jax.Array,
) -> SimulationState:
    """Advance the simulation by one step using substepped dynamics."""

    num_substeps = max(int(config.dynamics_substeps), 1)
    dt_total = config.dt
    dt = dt_total / num_substeps
    robot_linear_cmd = jnp.clip(
        robot_actions[..., 0], -config.max_robot_speed, config.max_robot_speed
    )
    robot_angular_cmd = jnp.clip(
        robot_actions[..., 1], -config.max_robot_angular_speed, config.max_robot_angular_speed
    )

    def resolve_positions(positions, radius):
        return _resolve_axis_aligned_collisions(
            positions, radius, map_batch.segments, map_batch.segment_mask
        )

    noise_scale = config.person_noise_scale * jnp.sqrt(
        dt / jnp.maximum(dt_total, 1e-6)
    )

    def fori_body(_, carry):
        robot_positions, headings, people_positions, people_velocity, key_inner = carry
        key_inner, noise_key = jax.random.split(key_inner)

        heading_dirs = jnp.stack([jnp.cos(headings), jnp.sin(headings)], axis=-1)
        robot_positions = robot_positions + dt * (robot_linear_cmd[..., None] * heading_dirs)
        headings = _wrap_angle(headings + dt * robot_angular_cmd)

        people_noise = noise_scale * jax.random.normal(noise_key, people_velocity.shape)
        people_velocity = _clip_speed(people_velocity + people_noise, config.max_person_speed)
        people_positions = people_positions + dt * people_velocity

        robot_positions = resolve_positions(robot_positions, config.robot_radius)
        people_positions = resolve_positions(people_positions, config.person_radius)

        return robot_positions, headings, people_positions, people_velocity, key_inner

    robot_positions, headings, people_positions, people_velocity, final_key = jax.lax.fori_loop(
        0,
        num_substeps,
        fori_body,
        (
            state.robots.position,
            state.robots.heading,
            state.people.position,
            state.people.velocity,
            key,
        ),
    )
    del final_key

    heading_dirs_out = jnp.stack([jnp.cos(headings), jnp.sin(headings)], axis=-1)
    robot_velocity_out = robot_linear_cmd[..., None] * heading_dirs_out
    robots = RobotState(position=robot_positions, velocity=robot_velocity_out, heading=headings)
    people = PeopleState(position=people_positions, velocity=people_velocity)
    return SimulationState(robots=robots, people=people)

def lidar_scan(
    origin: jnp.ndarray,
    angles: jnp.ndarray,
    max_range: float,
    map_batch: IndoorMapBatch,
    *,
    people_positions: jnp.ndarray | None = None,
    person_radius: float = 0.0,
    num_subsamples: int = 1,
    origin_velocities: jnp.ndarray | None = None,
    people_velocities: jnp.ndarray | None = None,
    dt: float | None = None,
    return_history: bool = False,
) -> jnp.ndarray | tuple[jnp.ndarray, jnp.ndarray]:
    """Optimized batched lidar ray casting with better performance."""
    
    # Precompute ray directions and properties
    directions = jnp.stack([jnp.cos(angles), jnp.sin(angles)], axis=-1)  # (A, 2)
    max_range_val = jnp.minimum(jnp.asarray(max_range, dtype=origin.dtype), 30.0)
    
    # Handle optional inputs
    if people_positions is None:
        people_positions = jnp.zeros((origin.shape[0], 0, 2), dtype=origin.dtype)
    if origin_velocities is None:
        origin_velocities = jnp.zeros_like(origin)
    if people_velocities is None:
        people_velocities = jnp.zeros_like(people_positions)

    # Precompute segment properties
    segments = map_batch.segments  # (B, S, 4)
    segment_mask = map_batch.segment_mask  # (B, S)
    
    # Precompute ray properties
    ray_dx = directions[:, 0]  # (A,)
    ray_dy = directions[:, 1]  # (A,)
    ray_norm_sq = jnp.sum(directions * directions, axis=-1)  # (A,)
    
    # Safe inverses for ray directions to avoid division by zero
    safe_inv_dx = jnp.where(jnp.abs(ray_dx) > 1e-8, 1.0 / ray_dx, jnp.inf)
    safe_inv_dy = jnp.where(jnp.abs(ray_dy) > 1e-8, 1.0 / ray_dy, jnp.inf)

    def cast_single_environment(origin_env, segments_env, seg_mask_env, people_env):
        """Cast rays for a single environment."""
        
        # Extract segment properties for this environment
        x0, y0, x1, y1 = jnp.moveaxis(segments_env, -1, 0)  # (S,) each
        vertical = jnp.isclose(x0, x1)
        horizontal = jnp.isclose(y0, y1)
        
        # Precompute segment bounds
        x_min = jnp.minimum(x0, x1)
        x_max = jnp.maximum(x0, x1)
        y_min = jnp.minimum(y0, y1)
        y_max = jnp.maximum(y0, y1)
        
        def cast_single_robot(origin_robot):
            """Cast all rays for a single robot position."""
            ox, oy = origin_robot
            
            # Vectorized wall intersections - Vertical segments
            t_vertical = (x0[None, :] - ox) * safe_inv_dx[:, None]  # (A, S)
            y_hit = oy + t_vertical * ray_dy[:, None]
            hit_vertical = (
                seg_mask_env[None, :] & vertical[None, :] &
                (t_vertical > 1e-8) & (t_vertical <= max_range_val) &
                (y_hit >= y_min[None, :]) & (y_hit <= y_max[None, :])
            )
            d_vertical = jnp.where(hit_vertical, t_vertical, jnp.inf)
            
            # Horizontal segments  
            t_horizontal = (y0[None, :] - oy) * safe_inv_dy[:, None]  # (A, S)
            x_hit = ox + t_horizontal * ray_dx[:, None]
            hit_horizontal = (
                seg_mask_env[None, :] & horizontal[None, :] &
                (t_horizontal > 1e-8) & (t_horizontal <= max_range_val) &
                (x_hit >= x_min[None, :]) & (x_hit <= x_max[None, :])
            )
            d_horizontal = jnp.where(hit_horizontal, t_horizontal, jnp.inf)
            
            # Combine wall distances
            min_wall_dist = jnp.minimum(jnp.min(d_vertical, axis=1), 
                                      jnp.min(d_horizontal, axis=1))
            
            # People intersections (only if people exist)
            def compute_people_intersections():
                # Vectorized circle-ray intersections
                rel_pos = origin_robot - people_env  # (P, 2)
                a = ray_norm_sq  # (A,)
                b = 2.0 * jnp.einsum('a,pa->ap', directions, rel_pos)  # (A, P)
                c = jnp.sum(rel_pos * rel_pos, axis=-1) - person_radius**2  # (P,)
                
                # Solve quadratic equation
                discriminant = b**2 - 4 * a[:, None] * c[None, :]
                valid = discriminant >= 0
                
                sqrt_disc = jnp.sqrt(jnp.maximum(discriminant, 0.0))
                t0 = (-b - sqrt_disc) / (2 * a[:, None] + 1e-12)
                t1 = (-b + sqrt_disc) / (2 * a[:, None] + 1e-12)
                
                # Find smallest valid positive t
                t_people = jnp.where((t0 > 1e-8) & valid, t0, jnp.inf)
                t_people = jnp.minimum(t_people, jnp.where((t1 > 1e-8) & valid, t1, jnp.inf))
                
                return jnp.min(t_people, axis=1)  # (A,)
            
            min_people_dist = jax.lax.cond(
                people_env.shape[0] > 0,
                compute_people_intersections,
                lambda: jnp.full(angles.shape, jnp.inf)
            )
            
            # Combine all distances
            final_dist = jnp.minimum(min_wall_dist, min_people_dist)
            return jnp.minimum(final_dist, max_range_val)
        
        return jax.vmap(cast_single_robot)(origin_env)
    
    # Main scanning logic
    samples = max(int(num_subsamples), 1)
    if samples == 1:
        distances = jax.vmap(cast_single_environment)(
            origin, segments, segment_mask, people_positions
        )
        if return_history:
            return distances, distances[jnp.newaxis, ...]
        return distances
    
    # Temporal supersampling
    total_dt = 0.0 if dt is None else float(dt)
    sub_dt = jnp.asarray(total_dt / samples, dtype=origin.dtype)
    origin_delta = origin_velocities * sub_dt
    people_delta = people_velocities * sub_dt

    def scan_step(carry, _):
        origin_pos, people_pos = carry
        d = jax.vmap(cast_single_environment)(origin_pos, segments, segment_mask, people_pos)
        return (origin_pos + origin_delta, people_pos + people_delta), d

    (_, _), history = jax.lax.scan(
        scan_step, (origin, people_positions), None, length=samples
    )
    final = history[-1]
    
    return (final, history) if return_history else final




def render_lidar_scan_with_borders(
    state: SimulationState,
    map_batch: IndoorMapBatch,
    angles: jnp.ndarray,
    distances: jnp.ndarray,
    *,
    env_index: int = 0,
    robot_index: int = 0,
    ax=None,
    ray_alpha: float = 0.3,
    hit_point_size: float = 20.0
):
    """Render lidar scan ensuring rays visibly hit object borders.
    
    Compatible with existing rendering infrastructure.
    """
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    
    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 10))
    
    # Extract data for the specific environment
    env_segments = map_batch.segments[env_index]
    env_segment_mask = map_batch.segment_mask[env_index]
    robot_pos = state.robots.position[env_index, robot_index]
    people_pos = state.people.position[env_index] if state.people.position.shape[1] > 0 else jnp.zeros((0, 2))
    
    # Plot walls with thickness
    for j in range(env_segments.shape[0]):
        if env_segment_mask[j]:
            x0, y0, x1, y1 = env_segments[j]
            # Draw thick lines for walls
            ax.plot([x0, x1], [y0, y1], 'k-', linewidth=3, alpha=0.8, zorder=1)
    
    # Plot people as circles with borders
    for j in range(people_pos.shape[0]):
        person_pos = people_pos[j]
        if jnp.all(jnp.isfinite(person_pos)):
            circle = patches.Circle(
                person_pos, 
                0.2,  # person_radius
                fill=True, 
                color='red', 
                alpha=0.7,
                edgecolor='darkred',
                linewidth=2,
                zorder=2
            )
            ax.add_patch(circle)
    
    # Plot robot
    robot_circle = patches.Circle(
        robot_pos,
        0.2,  # robot_radius
        fill=True,
        color='blue',
        alpha=0.8,
        edgecolor='darkblue',
        linewidth=2,
        zorder=3
    )
    ax.add_patch(robot_circle)
    
    # Plot rays and hit points
    env_distances = distances[env_index, robot_index] if distances.ndim > 2 else distances[env_index]
    
    for ray_idx, angle in enumerate(angles):
        dist = env_distances[ray_idx]
        
        if jnp.isfinite(dist) and dist < 30.0:  # Valid hit
            end_point = robot_pos + dist * jnp.array([jnp.cos(angle), jnp.sin(angle)])
            
            # Draw ray
            ax.plot(
                [robot_pos[0], end_point[0]],
                [robot_pos[1], end_point[1]],
                'b-',
                alpha=ray_alpha,
                linewidth=1,
                zorder=1
            )
            
            # Emphasize hit point
            ax.scatter(
                end_point[0], end_point[1],
                s=hit_point_size,
                c='red',
                marker='o',
                alpha=0.8,
                edgecolors='darkred',
                linewidths=1,
                zorder=4
            )
    
    ax.set_aspect('equal')
    ax.set_xlabel('X (m)')
    ax.set_ylabel('Y (m)')
    ax.set_title(f'Lidar Scan - Env {env_index}, Robot {robot_index}')
    ax.grid(True, alpha=0.3)
    
    # Set reasonable plot limits based on typical map size
    ax.set_xlim(0, 20)
    ax.set_ylim(0, 20)
    
    return ax